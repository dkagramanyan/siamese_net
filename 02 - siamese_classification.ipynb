{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout,Activation, Lambda,LeakyReLU,ReLU\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,LayerNormalization,GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from image_utils import get_pairs,get_dataset_info,estimate_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define images main information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Dataset info\n",
      "\n",
      "image shape =  (128, 128, 3)\n",
      "image weight =  48.0  KiB\n",
      "number of classes =  4\n",
      "number of pictures =  164\n",
      "positive pairs count = 8506\n",
      "positive pairs images weight = 0.779  GiB\n",
      "negative pairs count = 18390\n",
      "negative pairs images weight = 1.684  GiB\n",
      "\n",
      "total memory size = 2.463  GiB\n"
     ]
    }
   ],
   "source": [
    "main_folder_name='sof dataset'\n",
    "#main_folder_name='saint georges dataset'\n",
    "get_dataset_info(main_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset parametrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Estimated info\n",
      "\n",
      "desired positive pairs count = 10000\n",
      "positive pairs images weight = 0.916  GiB\n",
      "\n",
      "desired negative pairs count = 10000\n",
      "negative pairs images weight = 0.916  GiB\n",
      "\n",
      "total memory size = 1.832  GiB\n"
     ]
    }
   ],
   "source": [
    "image_shape=(128,128,3)\n",
    "max_positive_pairs_count=10000\n",
    "max_negative_pairs_count=10000\n",
    "estimate_dataset(main_folder_name,\n",
    "                 max_positive_pairs_count,\n",
    "                 max_negative_pairs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocces the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation began\n",
      "\n",
      "Calculation is done\n",
      "\n",
      "passed seconds:  13.511  seconds\n"
     ]
    }
   ],
   "source": [
    "pairs,labels=get_pairs(main_folder_name,\n",
    "                       max_positive_pairs_count,\n",
    "                       max_negative_pairs_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs,test_pairs,train_labels,test_labels=train_test_split(pairs.astype('float16'),labels.astype('float16'),test_size=0.2)\n",
    "#train_pairs=tf.constant(train_pairs)\n",
    "#train_labels=tf.constant(train_labels)\n",
    "del pairs\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9296875\n",
      "0.732421875\n",
      "2.9802322387695312e-05\n",
      "7.450580596923828e-06\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "print(train_pairs.nbytes/1024**n)\n",
    "print(test_pairs.nbytes/1024**n)\n",
    "print(train_labels.nbytes/1024**n)\n",
    "print(test_labels.nbytes/1024**n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese pecularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As siamese network measure distance between we define Euclidean distance Lambda layer and special contrastive loss ( https://arxiv.org/abs/2011.02803 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "    \n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return K.mean( (1 - y_true) * square_pred+y_true*margin_square)\n",
    "    \n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #\n",
    "    #   it is also good idea to use VGG model, but it requires powerfull GPU\n",
    "    #   model = Sequential(VGG16(weights='imagenet', include_top=False, input_shape=image_shape).layers)\n",
    "    #\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16,(3,3),input_shape=image_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "        \n",
    "    model.add(Conv2D(64,(3,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = get_model()\n",
    "#base_network.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define siamese model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide weights sycronization we define left and right inputs with the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=image_shape)\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "input_b = Input(shape=image_shape)\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "x = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "output= Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 64)           3505632     input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           sequential_4[0][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            2           lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,505,634\n",
      "Trainable params: 3,505,474\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important*, 43 epochs take 4 hours to train on gxt 980 ti. Make sure, that you have enough computation power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "128/128 [==============================] - 12s 72ms/step - loss: 0.4995 - val_loss: 0.5174\n",
      "Epoch 2/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4960 - val_loss: 0.5174\n",
      "Epoch 3/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4983 - val_loss: 0.5174\n",
      "Epoch 4/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4877 - val_loss: 0.5174\n",
      "Epoch 5/17\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.4978 - val_loss: 0.5174\n",
      "Epoch 6/17\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.4976 - val_loss: 0.5174\n",
      "Epoch 7/17\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.4954 - val_loss: 0.5174\n",
      "Epoch 8/17\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.5049 - val_loss: 0.5174\n",
      "Epoch 9/17\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 0.4992 - val_loss: 0.5174\n",
      "Epoch 10/17\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.4964 - val_loss: 0.5174\n",
      "Epoch 11/17\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 0.5000 - val_loss: 0.5174\n",
      "Epoch 12/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4933 - val_loss: 0.5174\n",
      "Epoch 13/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4917 - val_loss: 0.5174\n",
      "Epoch 14/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4953 - val_loss: 0.5174\n",
      "Epoch 15/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.5078 - val_loss: 0.5174\n",
      "Epoch 16/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4966 - val_loss: 0.5174\n",
      "Epoch 17/17\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.4919 - val_loss: 0.5174\n"
     ]
    }
   ],
   "source": [
    "optim = RMSprop(  learning_rate=0.015)\n",
    "#optim = Adam(  learning_rate=0.015)\n",
    "model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=optim)\n",
    "history = model.fit([train_pairs[:,0],train_pairs[:,1]], \n",
    "                    train_labels, \n",
    "                    epochs=17, \n",
    "                    batch_size=100,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path='saved data'\n",
    "\n",
    "#weights_name='georges_weight.h5'\n",
    "#history_name='georges_history.json'\n",
    "\n",
    "weights_name='georges_weight.h5'\n",
    "history_name='georges_history.json'\n",
    "\n",
    "hist_json_file = saved_path+'/'+history_name\n",
    "weights_file=saved_path+'/' +weights_name\n",
    "\n",
    "model.save_weights(weights_file)\n",
    "hist_df = pd.DataFrame(history.history)  \n",
    "\n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network_network_network.save_weights('base_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path='saved data'\n",
    "\n",
    "#weights_name='human_weight.h5'\n",
    "#history_name='human_history.json'\n",
    "\n",
    "weights_name='georges_weight.h5'\n",
    "history_name='georges_history.json'\n",
    "\n",
    "hist_json_file = saved_path+'/'+history_name\n",
    "weights_file=saved_path+'/' +weights_name\n",
    "\n",
    "model.load_weights(weights_file)\n",
    "loaded_history=pd.read_json(hist_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loaded_history,title):\n",
    "    loss=loaded_history['loss']\n",
    "    val_loss=loaded_history['val_loss']\n",
    "    x=range(len(loss))\n",
    "    X=15\n",
    "    Y=8\n",
    "    plt.figure(figsize=(X,Y))\n",
    "    plt.plot(x,loss,'b',x,val_loss,'g')\n",
    "    plt.title(title, fontsize=20, fontname='Times New Roman')\n",
    "    plt.legend(['loss','val_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title='George losses per epoch'\n",
    "plot_loss(loaded_history,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "\n",
    "To compute accuracy of the model define rule: if predicted value is bigger, then 0.5, the result is 1, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() > 0.5\n",
    "    return round(np.mean(pred == y_true),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = round(model.evaluate(x=[test_pairs[:,0],test_pairs[:,1]], y=test_labels),4)\n",
    "\n",
    "y_pred_train = model.predict([test_pairs[:,0], test_pairs[:,1]])\n",
    "train_accuracy = compute_accuracy(test_labels, y_pred_train)\n",
    "\n",
    "y_pred_test = model.predict([test_pairs[:,0], test_pairs[:,1]])\n",
    "test_accuracy = compute_accuracy(test_labels, y_pred_test)\n",
    "\n",
    "print(\"Loss = {}, Train Accuracy = {} Test Accuracy = {}\".format(loss, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
